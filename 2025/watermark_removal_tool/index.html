<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>使用神经网络方法的视频水印消除 | Triority's blog</title><meta name="author" content="Triority"><meta name="copyright" content="Triority"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="用于消除去西藏的无人机视频素材的osd数据。以及最近的情况（好几个月没有更新文章啦）">
<meta property="og:type" content="article">
<meta property="og:title" content="使用神经网络方法的视频水印消除">
<meta property="og:url" content="http://triority.cc/2025/watermark_removal_tool/index.html">
<meta property="og:site_name" content="Triority&#39;s blog">
<meta property="og:description" content="用于消除去西藏的无人机视频素材的osd数据。以及最近的情况（好几个月没有更新文章啦）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://triority.cc/img/0628.png">
<meta property="article:published_time" content="2025-10-16T14:58:41.782Z">
<meta property="article:modified_time" content="2025-10-16T14:58:41.782Z">
<meta property="article:author" content="Triority">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="C++">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://triority.cc/img/0628.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://triority.cc/2025/watermark_removal_tool/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":10,"unescape":true,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '使用神经网络方法的视频水印消除',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-10-16 14:58:41'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><style type="text/css">
.spoiler {
  display: inline-flex;
}
p.spoiler {
  display: flex;
}
.spoiler a {
  pointer-events: none;
}
.spoiler-blur, .spoiler-blur > * {
  transition: text-shadow .5s ease;
}
.spoiler .spoiler-blur, .spoiler .spoiler-blur > * {
  color: rgba(0, 0, 0, 0);
  background-color: rgba(0, 0, 0, 0);
  text-shadow: 0 0 10px grey;
  cursor: pointer;
}
.spoiler .spoiler-blur:hover, .spoiler .spoiler-blur:hover > * {
  text-shadow: 0 0 5px grey;
}
.spoiler-box, .spoiler-box > * {
  transition: color .5s ease,
  background-color .5s ease;
}
.spoiler .spoiler-box, .spoiler .spoiler-box > * {
  color: black;
  background-color: black;
  text-shadow: none;
}</style><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="Triority's blog" type="application/atom+xml">
<script src="/assets/js/DPlayer.min.js"></script></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">124</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">36</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/services/"><i class="fa-fw fas fa-list"></i><span> 服务</span></a></div><div class="menus_item"><a class="site-page" href="/photo/"><i class="fa-fw fas fa-book"></i><span> 相册</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url('/img/0628.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Triority's blog"><img class="site-icon" src="/img/favicon.png"/><span class="site-name">Triority's blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/services/"><i class="fa-fw fas fa-list"></i><span> 服务</span></a></div><div class="menus_item"><a class="site-page" href="/photo/"><i class="fa-fw fas fa-book"></i><span> 相册</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">使用神经网络方法的视频水印消除</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2025-10-16T14:58:41.782Z" title="发表于 2025-10-16 14:58:41">2025-10-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%96%87%E6%A1%A3-%E7%AC%94%E8%AE%B0/">文档&amp;笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">10.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>50分钟</span></span><span class="post-meta-separator">|</span><span class="leancloud_visitors" id="/2025/watermark_removal_tool/" data-flag-title="使用神经网络方法的视频水印消除"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span class="leancloud-visitors-count"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="近期情况"><a href="#近期情况" class="headerlink" title="近期情况"></a>近期情况</h1><p>已经几个月没有在网站上更新文章了，已经到了被朋友催更的地步。一部分原因是前段时间在忙活毕业的事情，包括毕业论文和期末考试给我折磨的死去活来（主要是期末考试）；另一部分原因是一直在填坑，之前的好多项目做了一半没做完的，都在接着做，所有虽然没有新建文章但是之前的文章是一直在更新的啦</p>
<p>七月初毕业回家，全家出去玩了几天，回来之后开始谋划我都毕业旅行，打算去西藏和深圳。可惜去西藏的半个月花光了存款，深圳只好暂时放弃，不过考虑到温度，深圳香港寒假再去也是明智的选择。去西藏的经历的文章稍后推出（x</p>
<p>虽然原计划八月份要回学校干活了，但是宿舍没有解决，要在家等到9.2开学再去学校了。计划学点东西，包括深度学习，模电，信号处理（显然后两个是为自制短波台准备的，九月份开学去考b类操作证）以及背点单词准备六级。</p>
<p>去西藏无人机拍摄的素材有osd数据的叠加，虽然已经有现成的软件去除水印，但是吧神经网络学过那么久了从来没正经用过（pytorch学习笔记是已经有两年之久的2023年的文章了），于是就有了这篇文章</p>
<h1 id="水印数据"><a href="#水印数据" class="headerlink" title="水印数据"></a>水印数据</h1><p><img src="/2025/watermark_removal_tool/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20250812155953.png"><br>上图即为穿越机拍摄的视频的截图。为了训练这个神经网络，首先需要大量对应的无水印视频和水印视频。电脑的机械硬盘里有大概700G的电影，都是没有任何水印的蓝光原盘高码率视频，除了超高码率的缺点以外非常适合用来生成数据集。最开始想直接做视频截取图片叠加水印，已经写好了视频抽帧的程序，但是后来想到应该让网络学习连续的帧片段而不是单独处理每一张图片，否则视频的连贯性肯定要出问题。反正两个造数据的程序都放在下面</p>
<p><code>video2img.py</code>:视频截取图片。由于视频码率很高处理特别慢还写了多进程<del>写了我好几个小时还没用上</del></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_processes = multiprocessing.cpu_count()</span><br><span class="line">img_time_interval = <span class="number">5</span></span><br><span class="line">img_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">img_Dir = <span class="string">&#x27;data\img&#x27;</span></span><br><span class="line">video_Dir = <span class="string">&#x27;D:\movie\data&#x27;</span></span><br><span class="line">video_Type = <span class="string">&#x27;.mkv&#x27;</span></span><br><span class="line">start_frame_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">video2img</span>(<span class="params">video_path, img_path, interval, size, progress_queue, shared_total_counter</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(img_path):</span><br><span class="line">        os.makedirs(img_path)</span><br><span class="line">    cap = cv2.VideoCapture(video_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> cap.isOpened():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error: Could not open file <span class="subst">&#123;video_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    fps = cap.get(cv2.CAP_PROP_FPS)</span><br><span class="line">    total_frames = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_COUNT))</span><br><span class="line">    frame_interval = <span class="built_in">int</span>(fps * interval)</span><br><span class="line">    <span class="keyword">if</span> frame_interval == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Error: Frame interval is calculated as 0.&quot;</span>)</span><br><span class="line">        cap.release()</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    frame_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> cap.isOpened():</span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> frame_count % frame_interval == <span class="number">0</span>:</span><br><span class="line">            frame = cv2.resize(frame, size)</span><br><span class="line">            output_image_path = os.path.join(img_path, <span class="string">f&quot;Frame_<span class="subst">&#123;shared_total_counter.value&#125;</span>.jpg&quot;</span>)</span><br><span class="line">            cv2.imwrite(output_image_path, frame)</span><br><span class="line">            shared_total_counter.value += <span class="number">1</span></span><br><span class="line">        frame_count += <span class="number">1</span></span><br><span class="line">        progress_queue.put(<span class="number">1</span>)</span><br><span class="line">    cap.release()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_video_files</span>(<span class="params">directory, file_type=<span class="string">&quot;.mkv&quot;</span></span>):</span><br><span class="line">    mkv_files_list = []</span><br><span class="line">    <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(directory):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            <span class="keyword">if</span> file.endswith(file_type):</span><br><span class="line">                full_path = os.path.join(root, file)</span><br><span class="line">                mkv_files_list.append(full_path)</span><br><span class="line">    <span class="keyword">return</span> mkv_files_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    video_path_list = find_video_files(video_Dir, video_Type)</span><br><span class="line">    frame_total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> video_path_list:</span><br><span class="line">        cap = cv2.VideoCapture(i)</span><br><span class="line">        frame_total = frame_total + <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_COUNT))</span><br><span class="line">        cap.release()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;The total number of frames of the video is <span class="subst">&#123;frame_total&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    manager = multiprocessing.Manager()</span><br><span class="line">    progress_queue = manager.Queue()</span><br><span class="line">    frame_completed = <span class="number">0</span></span><br><span class="line">    shared_total_counter = manager.Value(<span class="string">&#x27;i&#x27;</span>, start_frame_num)</span><br><span class="line">    pool = multiprocessing.Pool(processes=num_processes)</span><br><span class="line">    pbar = tqdm(total=frame_total, desc=<span class="string">&quot;Video frame processing&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> video_path_list:</span><br><span class="line">        pool.apply_async(video2img, args=(i, img_Dir, img_time_interval, img_size, progress_queue, shared_total_counter))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> frame_completed &lt; frame_total:</span><br><span class="line">        _ = progress_queue.get()</span><br><span class="line">        frame_completed += <span class="number">1</span></span><br><span class="line">        pbar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    pbar.close()</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nCompleted!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>video_mask.py</code>:视频截取指定帧长度的视频，并随机生成文字掩膜，保存视频片段、带水印的视频片段和掩膜图片。这个程序大部分是用Google AI Studio写的</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_processes = multiprocessing.cpu_count()</span><br><span class="line">img_time_interval = <span class="number">5</span></span><br><span class="line">img_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">img_Dir = <span class="string">&#x27;data\img&#x27;</span></span><br><span class="line">video_Dir = <span class="string">&#x27;D:\movie\data&#x27;</span></span><br><span class="line">video_Type = <span class="string">&#x27;.mkv&#x27;</span></span><br><span class="line">start_frame_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">video2img</span>(<span class="params">video_path, img_path, interval, size, progress_queue, shared_total_counter</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(img_path):</span><br><span class="line">        os.makedirs(img_path)</span><br><span class="line">    cap = cv2.VideoCapture(video_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> cap.isOpened():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error: Could not open file <span class="subst">&#123;video_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    fps = cap.get(cv2.CAP_PROP_FPS)</span><br><span class="line">    total_frames = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_COUNT))</span><br><span class="line">    frame_interval = <span class="built_in">int</span>(fps * interval)</span><br><span class="line">    <span class="keyword">if</span> frame_interval == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Error: Frame interval is calculated as 0.&quot;</span>)</span><br><span class="line">        cap.release()</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    frame_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> cap.isOpened():</span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> frame_count % frame_interval == <span class="number">0</span>:</span><br><span class="line">            frame = cv2.resize(frame, size)</span><br><span class="line">            output_image_path = os.path.join(img_path, <span class="string">f&quot;Frame_<span class="subst">&#123;shared_total_counter.value&#125;</span>.jpg&quot;</span>)</span><br><span class="line">            cv2.imwrite(output_image_path, frame)</span><br><span class="line">            shared_total_counter.value += <span class="number">1</span></span><br><span class="line">        frame_count += <span class="number">1</span></span><br><span class="line">        progress_queue.put(<span class="number">1</span>)</span><br><span class="line">    cap.release()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_video_files</span>(<span class="params">directory, file_type=<span class="string">&quot;.mkv&quot;</span></span>):</span><br><span class="line">    mkv_files_list = []</span><br><span class="line">    <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(directory):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            <span class="keyword">if</span> file.endswith(file_type):</span><br><span class="line">                full_path = os.path.join(root, file)</span><br><span class="line">                mkv_files_list.append(full_path)</span><br><span class="line">    <span class="keyword">return</span> mkv_files_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    video_path_list = find_video_files(video_Dir, video_Type)</span><br><span class="line">    frame_total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> video_path_list:</span><br><span class="line">        cap = cv2.VideoCapture(i)</span><br><span class="line">        frame_total = frame_total + <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_COUNT))</span><br><span class="line">        cap.release()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;The total number of frames of the video is <span class="subst">&#123;frame_total&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    manager = multiprocessing.Manager()</span><br><span class="line">    progress_queue = manager.Queue()</span><br><span class="line">    frame_completed = <span class="number">0</span></span><br><span class="line">    shared_total_counter = manager.Value(<span class="string">&#x27;i&#x27;</span>, start_frame_num)</span><br><span class="line">    pool = multiprocessing.Pool(processes=num_processes)</span><br><span class="line">    pbar = tqdm(total=frame_total, desc=<span class="string">&quot;Video frame processing&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> video_path_list:</span><br><span class="line">        pool.apply_async(video2img, args=(i, img_Dir, img_time_interval, img_size, progress_queue, shared_total_counter))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> frame_completed &lt; frame_total:</span><br><span class="line">        _ = progress_queue.get()</span><br><span class="line">        frame_completed += <span class="number">1</span></span><br><span class="line">        pbar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    pbar.close()</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nCompleted!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><p>由于要处理的数据是运动性极强的FPV视频，需要使用循环神经网络来让网络考虑上一帧内容，以及用卷积神经网络来恢复图像。因此使用带有ConvLSTM的U-Net结构。</p>
<p>输入图像经过4组卷积，维度扩展到512维，然后在这里通过ConvLSTM将当前信息和过去记忆拼接考虑，并通过四个门控更新记忆和生成输出和新的隐藏状态，再经过4组和前面卷积组有跳跃连接的转置卷积恢复图像尺寸，最终得到三维度的RGB输出</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvBlock, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.convblock = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.convblock(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvLSTMCell</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, kernel_size, bias</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvLSTMCell, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.input_dim = input_dim</span><br><span class="line">        <span class="variable language_">self</span>.hidden_dim = hidden_dim</span><br><span class="line">        <span class="variable language_">self</span>.kernel_size = kernel_size</span><br><span class="line">        <span class="variable language_">self</span>.padding = kernel_size[<span class="number">0</span>] // <span class="number">2</span>, kernel_size[<span class="number">1</span>] // <span class="number">2</span></span><br><span class="line">        <span class="variable language_">self</span>.bias = bias</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将输入门、遗忘门、输出门和细胞门的卷积操作合并计算</span></span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels=<span class="variable language_">self</span>.input_dim + <span class="variable language_">self</span>.hidden_dim,</span><br><span class="line">                              out_channels=<span class="number">4</span> * <span class="variable language_">self</span>.hidden_dim,  <span class="comment"># 4 for i, f, o, g gates</span></span><br><span class="line">                              kernel_size=<span class="variable language_">self</span>.kernel_size,</span><br><span class="line">                              padding=<span class="variable language_">self</span>.padding,</span><br><span class="line">                              bias=<span class="variable language_">self</span>.bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_tensor, cur_state</span>):</span><br><span class="line">        h_cur, c_cur = cur_state</span><br><span class="line">        combined = torch.cat([input_tensor, h_cur], dim=<span class="number">1</span>)</span><br><span class="line">        combined_conv = <span class="variable language_">self</span>.conv(combined)</span><br><span class="line">        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, <span class="variable language_">self</span>.hidden_dim, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算4*门</span></span><br><span class="line">        i = torch.sigmoid(cc_i)</span><br><span class="line">        f = torch.sigmoid(cc_f)</span><br><span class="line">        o = torch.sigmoid(cc_o)</span><br><span class="line">        g = torch.tanh(cc_g)</span><br><span class="line">        c_next = f * c_cur + i * g</span><br><span class="line">        h_next = o * torch.tanh(c_next)</span><br><span class="line">        <span class="keyword">return</span> h_next, c_next</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self, batch_size, image_size</span>):</span><br><span class="line">        height, width = image_size</span><br><span class="line">        <span class="keyword">return</span> (torch.zeros(batch_size, <span class="variable language_">self</span>.hidden_dim, height, width, device=<span class="variable language_">self</span>.conv.weight.device),</span><br><span class="line">                torch.zeros(batch_size, <span class="variable language_">self</span>.hidden_dim, height, width, device=<span class="variable language_">self</span>.conv.weight.device))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RecurrentUNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, out_channels=<span class="number">3</span>, features=[<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span>):</span><br><span class="line">        <span class="built_in">super</span>(RecurrentUNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.downs = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.ups = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编码器</span></span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">            <span class="variable language_">self</span>.downs.append(ConvBlock(in_channels, feature))</span><br><span class="line">            in_channels = feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ConvLSTM瓶颈</span></span><br><span class="line">        <span class="variable language_">self</span>.bottleneck_dim = features[-<span class="number">1</span>]</span><br><span class="line">        <span class="variable language_">self</span>.conv_lstm = ConvLSTMCell(input_dim=<span class="variable language_">self</span>.bottleneck_dim,</span><br><span class="line">                                      hidden_dim=<span class="variable language_">self</span>.bottleneck_dim,</span><br><span class="line">                                      kernel_size=(<span class="number">3</span>, <span class="number">3</span>), bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码器</span></span><br><span class="line">        in_channels = features[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> <span class="built_in">reversed</span>(features):</span><br><span class="line">            <span class="variable language_">self</span>.ups.append(nn.ConvTranspose2d(in_channels, feature, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">            <span class="variable language_">self</span>.ups.append(ConvBlock(feature * <span class="number">2</span>, feature))</span><br><span class="line">            in_channels = feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出</span></span><br><span class="line">        <span class="variable language_">self</span>.final_conv = nn.Conv2d(features[<span class="number">0</span>], out_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, hidden_state=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 视频片段x的期望形状:[batch_size, sequence_length, Channels, H, W]</span></span><br><span class="line">        batch_size, seq_len, _, H, W = x.shape</span><br><span class="line">        <span class="keyword">if</span> hidden_state <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            bottleneck_h, bottleneck_w = H // (<span class="number">2</span> ** (<span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>)), W // (<span class="number">2</span> ** (<span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>))</span><br><span class="line">            hidden_state = <span class="variable language_">self</span>.conv_lstm.init_hidden(batch_size, (bottleneck_h, bottleneck_w))</span><br><span class="line">        outputs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 序列帧循环</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(seq_len):</span><br><span class="line">            current_frame = x[:, t, :, :, :]</span><br><span class="line">            skip_connections_t = []</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 编码器</span></span><br><span class="line">            <span class="keyword">for</span> i, down <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.downs):</span><br><span class="line">                current_frame = down(current_frame)</span><br><span class="line">                skip_connections_t.append(current_frame)</span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>:</span><br><span class="line">                    current_frame = <span class="variable language_">self</span>.pool(current_frame)</span><br><span class="line">            <span class="comment"># ConvLSTM</span></span><br><span class="line">            h, c = <span class="variable language_">self</span>.conv_lstm(input_tensor=current_frame, cur_state=hidden_state)</span><br><span class="line">            hidden_state = (h, c)</span><br><span class="line">            current_frame = h</span><br><span class="line">            <span class="comment"># 反转跳跃连接列表</span></span><br><span class="line">            skip_connections_t = skip_connections_t[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 解码器</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.ups), <span class="number">2</span>):</span><br><span class="line">                current_frame = <span class="variable language_">self</span>.ups[i](current_frame)</span><br><span class="line">                skip_connection = skip_connections_t[i // <span class="number">2</span>]</span><br><span class="line">                <span class="comment"># 如果池化导致奇数尺寸，上采样后的尺寸与跳跃连接不匹配，则强制修改尺寸</span></span><br><span class="line">                <span class="keyword">if</span> current_frame.shape != skip_connection.shape:</span><br><span class="line">                    current_frame = nn.functional.interpolate(current_frame, size=skip_connection.shape[<span class="number">2</span>:])</span><br><span class="line">                concat_skip = torch.cat((skip_connection, current_frame), dim=<span class="number">1</span>)</span><br><span class="line">                current_frame = <span class="variable language_">self</span>.ups[i + <span class="number">1</span>](concat_skip)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 生成帧</span></span><br><span class="line">            frame_output = <span class="variable language_">self</span>.final_conv(current_frame)</span><br><span class="line">            outputs.append(frame_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.stack(outputs, dim=<span class="number">1</span>), hidden_state</span><br></pre></td></tr></table></figure>

<h1 id="改进和效果记录"><a href="#改进和效果记录" class="headerlink" title="改进和效果记录"></a>改进和效果记录</h1><h2 id="RGB三维输入"><a href="#RGB三维输入" class="headerlink" title="RGB三维输入"></a>RGB三维输入</h2><p>让网络直接学习加了水印的视频，训练了五轮的效果如下（由于显存限制，图像降低分辨率到480*270之后给网络计算）</p>
<table>
<thead>
<tr>
<th align="center"><div id="dplayer4" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer4"),"video":{"url":"/2025/watermark_removal_tool/b34be09f1bee268c4fc728776988c605.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
<th align="center"><div id="dplayer5" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer5"),"video":{"url":"/2025/watermark_removal_tool/9a9d89aef96d5c03e600bdaa5e65f646.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
</tr>
</thead>
<tbody><tr>
<td align="center">水印视频</td>
<td align="center">去水印视频</td>
</tr>
<tr>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
</tr>
</tbody></table>
<p>看起来网络已经学会了什么样的东西是文字水印并进行了一定处理。于是，为什么要让模型自己学习文字水印长啥样啊我明明有掩膜图片的，无人机视频也能用白色过滤选中水印区域啊，于是稍作修改，改成叠加了掩膜的四个通道输入</p>
<h2 id="RGB-Mask四维输入"><a href="#RGB-Mask四维输入" class="headerlink" title="RGB+Mask四维输入"></a>RGB+Mask四维输入</h2><p><code>train.py</code>: 训练程序</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms.functional <span class="keyword">as</span> TF</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvBlock, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.convblock = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.convblock(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvLSTMCell</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, kernel_size, bias</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvLSTMCell, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.input_dim = input_dim</span><br><span class="line">        <span class="variable language_">self</span>.hidden_dim = hidden_dim</span><br><span class="line">        <span class="variable language_">self</span>.kernel_size = kernel_size</span><br><span class="line">        <span class="variable language_">self</span>.padding = kernel_size[<span class="number">0</span>] // <span class="number">2</span>, kernel_size[<span class="number">1</span>] // <span class="number">2</span></span><br><span class="line">        <span class="variable language_">self</span>.bias = bias</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将输入门、遗忘门、输出门和细胞门的卷积操作合并计算</span></span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels=<span class="variable language_">self</span>.input_dim + <span class="variable language_">self</span>.hidden_dim,</span><br><span class="line">                              out_channels=<span class="number">4</span> * <span class="variable language_">self</span>.hidden_dim,  <span class="comment"># 4 for i, f, o, g gates</span></span><br><span class="line">                              kernel_size=<span class="variable language_">self</span>.kernel_size,</span><br><span class="line">                              padding=<span class="variable language_">self</span>.padding,</span><br><span class="line">                              bias=<span class="variable language_">self</span>.bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_tensor, cur_state</span>):</span><br><span class="line">        h_cur, c_cur = cur_state</span><br><span class="line">        combined = torch.cat([input_tensor, h_cur], dim=<span class="number">1</span>)</span><br><span class="line">        combined_conv = <span class="variable language_">self</span>.conv(combined)</span><br><span class="line">        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, <span class="variable language_">self</span>.hidden_dim, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算4*门</span></span><br><span class="line">        i = torch.sigmoid(cc_i)</span><br><span class="line">        f = torch.sigmoid(cc_f)</span><br><span class="line">        o = torch.sigmoid(cc_o)</span><br><span class="line">        g = torch.tanh(cc_g)</span><br><span class="line">        c_next = f * c_cur + i * g</span><br><span class="line">        h_next = o * torch.tanh(c_next)</span><br><span class="line">        <span class="keyword">return</span> h_next, c_next</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self, batch_size, image_size</span>):</span><br><span class="line">        height, width = image_size</span><br><span class="line">        <span class="keyword">return</span> (torch.zeros(batch_size, <span class="variable language_">self</span>.hidden_dim, height, width, device=<span class="variable language_">self</span>.conv.weight.device),</span><br><span class="line">                torch.zeros(batch_size, <span class="variable language_">self</span>.hidden_dim, height, width, device=<span class="variable language_">self</span>.conv.weight.device))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RecurrentUNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, out_channels=<span class="number">3</span>, features=[<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span>):</span><br><span class="line">        <span class="built_in">super</span>(RecurrentUNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.downs = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.ups = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编码器</span></span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">            <span class="variable language_">self</span>.downs.append(ConvBlock(in_channels, feature))</span><br><span class="line">            in_channels = feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ConvLSTM瓶颈</span></span><br><span class="line">        <span class="variable language_">self</span>.bottleneck_dim = features[-<span class="number">1</span>]</span><br><span class="line">        <span class="variable language_">self</span>.conv_lstm = ConvLSTMCell(input_dim=<span class="variable language_">self</span>.bottleneck_dim,</span><br><span class="line">                                      hidden_dim=<span class="variable language_">self</span>.bottleneck_dim,</span><br><span class="line">                                      kernel_size=(<span class="number">3</span>, <span class="number">3</span>), bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码器</span></span><br><span class="line">        in_channels = features[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> <span class="built_in">reversed</span>(features):</span><br><span class="line">            <span class="variable language_">self</span>.ups.append(nn.ConvTranspose2d(in_channels, feature, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">            <span class="variable language_">self</span>.ups.append(ConvBlock(feature * <span class="number">2</span>, feature))</span><br><span class="line">            in_channels = feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出</span></span><br><span class="line">        <span class="variable language_">self</span>.final_conv = nn.Conv2d(features[<span class="number">0</span>], out_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, hidden_state=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 视频片段x的期望形状:[batch_size, sequence_length, Channels, H, W]</span></span><br><span class="line">        batch_size, seq_len, _, H, W = x.shape</span><br><span class="line">        <span class="keyword">if</span> hidden_state <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            bottleneck_h, bottleneck_w = H // (<span class="number">2</span> ** (<span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>)), W // (<span class="number">2</span> ** (<span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>))</span><br><span class="line">            hidden_state = <span class="variable language_">self</span>.conv_lstm.init_hidden(batch_size, (bottleneck_h, bottleneck_w))</span><br><span class="line">        outputs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 序列帧循环</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(seq_len):</span><br><span class="line">            current_frame = x[:, t, :, :, :]</span><br><span class="line">            skip_connections_t = []</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 编码器</span></span><br><span class="line">            <span class="keyword">for</span> i, down <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.downs):</span><br><span class="line">                current_frame = down(current_frame)</span><br><span class="line">                skip_connections_t.append(current_frame)</span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>:</span><br><span class="line">                    current_frame = <span class="variable language_">self</span>.pool(current_frame)</span><br><span class="line">            <span class="comment"># ConvLSTM</span></span><br><span class="line">            h, c = <span class="variable language_">self</span>.conv_lstm(input_tensor=current_frame, cur_state=hidden_state)</span><br><span class="line">            hidden_state = (h, c)</span><br><span class="line">            current_frame = h</span><br><span class="line">            <span class="comment"># 反转跳跃连接列表</span></span><br><span class="line">            skip_connections_t = skip_connections_t[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 解码器</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.ups), <span class="number">2</span>):</span><br><span class="line">                current_frame = <span class="variable language_">self</span>.ups[i](current_frame)</span><br><span class="line">                skip_connection = skip_connections_t[i // <span class="number">2</span>]</span><br><span class="line">                <span class="comment"># 如果池化导致奇数尺寸，上采样后的尺寸与跳跃连接不匹配，则强制修改尺寸</span></span><br><span class="line">                <span class="keyword">if</span> current_frame.shape != skip_connection.shape:</span><br><span class="line">                    current_frame = nn.functional.interpolate(current_frame, size=skip_connection.shape[<span class="number">2</span>:])</span><br><span class="line">                concat_skip = torch.cat((skip_connection, current_frame), dim=<span class="number">1</span>)</span><br><span class="line">                current_frame = <span class="variable language_">self</span>.ups[i + <span class="number">1</span>](concat_skip)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 生成帧</span></span><br><span class="line">            frame_output = <span class="variable language_">self</span>.final_conv(current_frame)</span><br><span class="line">            outputs.append(frame_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.stack(outputs, dim=<span class="number">1</span>), hidden_state</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VideoDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, sequence_length=<span class="number">10</span>, transform=<span class="literal">None</span>, size=(<span class="params"><span class="number">480</span>, <span class="number">270</span></span>)</span>):</span><br><span class="line">        <span class="variable language_">self</span>.root_dir = pathlib.Path(root_dir)</span><br><span class="line">        <span class="variable language_">self</span>.clips_dir = <span class="variable language_">self</span>.root_dir / <span class="string">&#x27;clips&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.mask_clips_dir = <span class="variable language_">self</span>.root_dir / <span class="string">&#x27;mask_clips&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.mask_dir = <span class="variable language_">self</span>.root_dir / <span class="string">&#x27;masks&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.clips_files = <span class="built_in">sorted</span>([p <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.clips_dir.glob(<span class="string">&#x27;*.mp4&#x27;</span>)])</span><br><span class="line">        <span class="variable language_">self</span>.mask_clips_files = <span class="built_in">sorted</span>([p <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.mask_clips_dir.glob(<span class="string">&#x27;*.mp4&#x27;</span>)])</span><br><span class="line">        <span class="variable language_">self</span>.mask_files = <span class="built_in">sorted</span>([p <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.mask_dir.glob(<span class="string">&#x27;*.png&#x27;</span>)])</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.clips_files) == <span class="built_in">len</span>(<span class="variable language_">self</span>.mask_clips_files) == <span class="built_in">len</span>(<span class="variable language_">self</span>.mask_files), <span class="string">&quot;The number of dataset files does not match!&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.sequence_length = sequence_length</span><br><span class="line">        <span class="variable language_">self</span>.transform = transform</span><br><span class="line">        <span class="comment"># 输入格式(width, height)，PyTorch(height, width)</span></span><br><span class="line">        <span class="variable language_">self</span>.target_size = size</span><br><span class="line">        <span class="variable language_">self</span>.target_size_torch = (size[<span class="number">1</span>], size[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.clips_files)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        clips_path = <span class="built_in">str</span>(<span class="variable language_">self</span>.clips_files[idx])</span><br><span class="line">        mask_clips_path = <span class="built_in">str</span>(<span class="variable language_">self</span>.mask_clips_files[idx])</span><br><span class="line">        mask_path = <span class="built_in">str</span>(<span class="variable language_">self</span>.mask_files[idx])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">read_and_resize_frames</span>(<span class="params">video_path, num_frames, size</span>):</span><br><span class="line">            cap = cv2.VideoCapture(video_path)</span><br><span class="line">            total_frames = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_COUNT))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> total_frames &lt; num_frames:</span><br><span class="line">                cap.release()</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Video <span class="subst">&#123;video_path&#125;</span> : total_frames (<span class="subst">&#123;total_frames&#125;</span>) &lt; num_frames (<span class="subst">&#123;num_frames&#125;</span>)。&quot;</span>)</span><br><span class="line"></span><br><span class="line">            frames = []</span><br><span class="line">            start_frame_index = <span class="number">0</span></span><br><span class="line">            cap.<span class="built_in">set</span>(cv2.CAP_PROP_POS_FRAMES, start_frame_index)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_frames):</span><br><span class="line">                ret, frame = cap.read()</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                frame_resized = cv2.resize(frame, size, interpolation=cv2.INTER_AREA)</span><br><span class="line"></span><br><span class="line">                frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)</span><br><span class="line">                frames.append(TF.to_tensor(frame_rgb))</span><br><span class="line">            cap.release()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(frames) != num_frames:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Read frame failed: <span class="subst">&#123;video_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> torch.stack(frames)</span><br><span class="line"></span><br><span class="line">        clips_seq = read_and_resize_frames(clips_path, <span class="variable language_">self</span>.sequence_length, <span class="variable language_">self</span>.target_size)</span><br><span class="line">        masked_seq = read_and_resize_frames(mask_clips_path, <span class="variable language_">self</span>.sequence_length, <span class="variable language_">self</span>.target_size)</span><br><span class="line">        mask_image = torchvision.io.read_image(<span class="built_in">str</span>(mask_path))</span><br><span class="line">        mask_image_resized = TF.resize(mask_image, <span class="variable language_">self</span>.target_size_torch, antialias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 归一化</span></span><br><span class="line">        clips_seq = clips_seq * <span class="number">2.0</span> - <span class="number">1.0</span></span><br><span class="line">        masked_seq = masked_seq * <span class="number">2.0</span> - <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">        mask_seq = mask_image_resized.<span class="built_in">float</span>() / <span class="number">255.0</span></span><br><span class="line">        mask_seq[mask_seq &gt; <span class="number">0.5</span>] = <span class="number">1.0</span></span><br><span class="line">        mask_seq[mask_seq &lt;= <span class="number">0.5</span>] = <span class="number">0.0</span></span><br><span class="line">        mask_seq = mask_seq.unsqueeze(<span class="number">0</span>).repeat(<span class="variable language_">self</span>.sequence_length, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        mask_seq = mask_seq[:, <span class="number">0</span>:<span class="number">1</span>, :, :]</span><br><span class="line">        masked_seq = torch.cat((masked_seq, mask_seq), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.transform:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> masked_seq, clips_seq, mask_seq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    lr = <span class="number">1e-4</span></span><br><span class="line">    batch_size = <span class="number">2</span></span><br><span class="line">    epochs = <span class="number">50</span></span><br><span class="line">    sequence_len = <span class="number">4</span></span><br><span class="line">    size = (<span class="number">480</span>, <span class="number">270</span>)</span><br><span class="line">    dataset_loader_workers = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    dataset_path = <span class="string">&quot;D:\Dataset&quot;</span></span><br><span class="line">    <span class="comment"># 继续训练时加载模型路径和已完成轮次，路径为空字符串则从零开始训练且设置的轮次无效</span></span><br><span class="line">    load_model_path = <span class="string">&quot;model\epoch_7.pth&quot;</span></span><br><span class="line">    load_model_epoch = <span class="number">7</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Using device: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line">    model = RecurrentUNet(in_channels=<span class="number">4</span>, out_channels=<span class="number">3</span>).to(device)</span><br><span class="line">    <span class="keyword">if</span> load_model_path == <span class="string">&quot;&quot;</span>:</span><br><span class="line">        load_model_epoch = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model.load_state_dict(torch.load(load_model_path, map_location=device))</span><br><span class="line"></span><br><span class="line">    criterion = nn.L1Loss()</span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=lr)</span><br><span class="line"></span><br><span class="line">    num_params = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Model has <span class="subst">&#123;num_params:,&#125;</span> trainable parameters.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Preparing dataset...&quot;</span>)</span><br><span class="line">    train_dataset = VideoDataset(root_dir=dataset_path, sequence_length=sequence_len, size=size)</span><br><span class="line">    train_loader = DataLoader(</span><br><span class="line">        dataset=train_dataset,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=<span class="literal">True</span>,</span><br><span class="line">        num_workers=dataset_loader_workers,</span><br><span class="line">        pin_memory=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Start training...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(load_model_epoch, epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        total_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">with</span> tqdm(total=<span class="built_in">len</span>(train_loader), desc=<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>&quot;</span>, unit=<span class="string">&quot;batch&quot;</span>) <span class="keyword">as</span> pbar:</span><br><span class="line">            <span class="keyword">for</span> batch_idx, (masked_seq, clips_seq, mask_seq) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">                masked_seq = masked_seq.to(device)</span><br><span class="line">                clips_seq = clips_seq.to(device)</span><br><span class="line">                mask_seq = mask_seq.to(device)</span><br><span class="line"></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                restored_seq, h_last = model(masked_seq)</span><br><span class="line"></span><br><span class="line">                loss = criterion(restored_seq, clips_seq)</span><br><span class="line">                loss.backward()</span><br><span class="line">                optimizer.step()</span><br><span class="line">                total_loss += loss.item()</span><br><span class="line"></span><br><span class="line">                pbar.set_postfix(loss=<span class="string">f&#x27;<span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">                pbar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        avg_loss = total_loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;--- <span class="subst">&#123;datetime.datetime.now():%H:%M:%S&#125;</span>: Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span> avg_loss: <span class="subst">&#123;avg_loss:<span class="number">.4</span>f&#125;</span> ---&quot;</span>)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">f&quot;model\epoch_<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Completed!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>infer.py</code>:有了训练的代码，这段程序就很容易了（懒得写了），以下内容由Google AI Studio生成。不要问为什么注释序号从2开始，因为第一部分被我整个删掉换成了<code>from train import RecurrentUNet</code></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms.functional <span class="keyword">as</span> TF</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> train <span class="keyword">import</span> RecurrentUNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"><span class="comment"># 2. 推理主函数</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">postprocess_and_write</span>(<span class="params">output_tensor, writer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;辅助函数：后处理并写入文件 (无需修改)&quot;&quot;&quot;</span></span><br><span class="line">    output_tensor = output_tensor.squeeze(<span class="number">0</span>).cpu()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(output_tensor.shape[<span class="number">0</span>]):</span><br><span class="line">        frame = (output_tensor[i] + <span class="number">1.0</span>) / <span class="number">2.0</span></span><br><span class="line">        frame = (frame.clamp(<span class="number">0</span>, <span class="number">1</span>) * <span class="number">255</span>).byte()</span><br><span class="line">        frame_np = frame.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).numpy()</span><br><span class="line">        frame_bgr = cv2.cvtColor(frame_np, cv2.COLOR_RGB2BGR)</span><br><span class="line">        writer.write(frame_bgr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">infer_video_4channel</span>(<span class="params">config</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用4通道输入(RGB+Mask)对视频进行分段推理。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    device = torch.device(config[<span class="string">&quot;device&quot;</span>])</span><br><span class="line">    target_size = config[<span class="string">&quot;input_size&quot;</span>]</span><br><span class="line">    target_size_torch = (target_size[<span class="number">1</span>], target_size[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在加载模型...&quot;</span>)</span><br><span class="line">    <span class="comment"># *** 关键改动: in_channels=4 ***</span></span><br><span class="line">    <span class="comment"># 模型输出仍然是修复后的RGB图像，所以 out_channels=3</span></span><br><span class="line">    model = RecurrentUNet(in_channels=<span class="number">4</span>, out_channels=<span class="number">3</span>).to(device)</span><br><span class="line">    model.load_state_dict(torch.load(config[<span class="string">&quot;model_path&quot;</span>], map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;模型已加载到设备: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --- 新增: 加载并预处理掩膜 ---</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;正在加载并处理掩膜: <span class="subst">&#123;config[<span class="string">&#x27;mask_path&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    mask_image = torchvision.io.read_image(config[<span class="string">&#x27;mask_path&#x27;</span>])</span><br><span class="line">    mask_resized = TF.resize(mask_image, target_size_torch, antialias=<span class="literal">True</span>)</span><br><span class="line">    mask_tensor = mask_resized.<span class="built_in">float</span>() / <span class="number">255.0</span></span><br><span class="line">    mask_tensor[mask_tensor &gt; <span class="number">0.5</span>] = <span class="number">1.0</span></span><br><span class="line">    mask_tensor[mask_tensor &lt;= <span class="number">0.5</span>] = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 确保是单通道 [1, H, W]，并放在CPU上以便和每帧拼接</span></span><br><span class="line">    mask_tensor_cpu = mask_tensor[<span class="number">0</span>:<span class="number">1</span>, :, :]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;正在处理输入视频: <span class="subst">&#123;config[<span class="string">&#x27;input_video_path&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    cap = cv2.VideoCapture(config[<span class="string">&quot;input_video_path&quot;</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> cap.isOpened():</span><br><span class="line">        <span class="keyword">raise</span> IOError(<span class="string">f&quot;无法打开视频文件: <span class="subst">&#123;config[<span class="string">&#x27;input_video_path&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    total_frames = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_COUNT))</span><br><span class="line">    original_fps = cap.get(cv2.CAP_PROP_FPS)</span><br><span class="line"></span><br><span class="line">    fourcc = cv2.VideoWriter_fourcc(*<span class="string">&#x27;VP09&#x27;</span>)</span><br><span class="line">    out_writer = cv2.VideoWriter(config[<span class="string">&quot;output_video_path&quot;</span>], fourcc, original_fps, target_size)</span><br><span class="line"></span><br><span class="line">    hidden_state = <span class="literal">None</span></span><br><span class="line">    chunk_frames = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">with</span> tqdm(total=total_frames, desc=<span class="string">&quot;正在推理&quot;</span>) <span class="keyword">as</span> pbar:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                ret, frame = cap.read()</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 1. 预处理RGB帧</span></span><br><span class="line">                frame_resized = cv2.resize(frame, target_size, interpolation=cv2.INTER_AREA)</span><br><span class="line">                frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)</span><br><span class="line">                frame_tensor_3ch = TF.to_tensor(frame_rgb) * <span class="number">2.0</span> - <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 2. *** 关键改动: 拼接成4通道输入 ***</span></span><br><span class="line">                <span class="comment"># torch.cat 沿着第0维(通道维)拼接 [3,H,W] 和 [1,H,W] -&gt; [4,H,W]</span></span><br><span class="line">                four_channel_tensor = torch.cat([frame_tensor_3ch, mask_tensor_cpu], dim=<span class="number">0</span>)</span><br><span class="line">                chunk_frames.append(four_channel_tensor)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(chunk_frames) == config[<span class="string">&quot;chunk_size&quot;</span>]:</span><br><span class="line">                    input_chunk = torch.stack(chunk_frames).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">                    restored_chunk, hidden_state = model(input_chunk, hidden_state)</span><br><span class="line">                    postprocess_and_write(restored_chunk, out_writer)</span><br><span class="line">                    chunk_frames = []</span><br><span class="line"></span><br><span class="line">                pbar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> chunk_frames:</span><br><span class="line">                pbar.set_description(<span class="string">&quot;处理最后一段&quot;</span>)</span><br><span class="line">                input_chunk = torch.stack(chunk_frames).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">                restored_chunk, hidden_state = model(input_chunk, hidden_state)</span><br><span class="line">                postprocess_and_write(restored_chunk, out_writer)</span><br><span class="line"></span><br><span class="line">    cap.release()</span><br><span class="line">    out_writer.release()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n视频推理完成并保存到: <span class="subst">&#123;config[<span class="string">&#x27;output_video_path&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"><span class="comment"># 3. 配置和执行</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inference_config = &#123;</span><br><span class="line">        <span class="string">&quot;model_path&quot;</span>: <span class="string">&quot;model/epoch_2.pth&quot;</span>,</span><br><span class="line">        <span class="comment"># 这是需要修复的视频，例如视频中某些区域被涂黑或有水印</span></span><br><span class="line">        <span class="string">&quot;input_video_path&quot;</span>: <span class="string">&quot;D:\Dataset\mask_clips\\0628.mp4&quot;</span>,</span><br><span class="line">        <span class="comment"># 这是对应的单张二值化掩膜图片，白色区域代表需要修复的地方</span></span><br><span class="line">        <span class="string">&quot;mask_path&quot;</span>: <span class="string">&quot;D:\Dataset\masks\\0628.png&quot;</span>,</span><br><span class="line">        <span class="string">&quot;output_video_path&quot;</span>: <span class="string">&quot;restored_video.mp4&quot;</span>,</span><br><span class="line">        <span class="string">&quot;input_size&quot;</span>: (<span class="number">480</span>, <span class="number">270</span>),</span><br><span class="line">        <span class="string">&quot;device&quot;</span>: <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>,</span><br><span class="line">        <span class="string">&quot;chunk_size&quot;</span>: <span class="number">10</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pathlib.Path(inference_config[<span class="string">&quot;model_path&quot;</span>]).exists():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;错误: 模型文件未找到 -&gt; <span class="subst">&#123;inference_config[<span class="string">&#x27;model_path&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> pathlib.Path(inference_config[<span class="string">&quot;input_video_path&quot;</span>]).exists():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;错误: 输入视频未找到 -&gt; <span class="subst">&#123;inference_config[<span class="string">&#x27;input_video_path&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 新增对掩膜文件路径的检查</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> pathlib.Path(inference_config[<span class="string">&quot;mask_path&quot;</span>]).exists():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;错误: 掩膜文件未找到 -&gt; <span class="subst">&#123;inference_config[<span class="string">&#x27;mask_path&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        infer_video_4channel(inference_config)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="center"><div id="dplayer6" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer6"),"video":{"url":"/2025/watermark_removal_tool/video_0628.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
<th align="center"><img src="/2025/watermark_removal_tool/mask0628.png"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">水印视频</td>
<td align="center">掩膜图片</td>
</tr>
<tr>
<td align="center"><div id="dplayer7" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer7"),"video":{"url":"/2025/watermark_removal_tool/restored_epoch2_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></td>
<td align="center"><div id="dplayer8" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer8"),"video":{"url":"/2025/watermark_removal_tool/restored_epoch8_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></td>
</tr>
<tr>
<td align="center">训练2轮去水印效果</td>
<td align="center">训练8轮去水印效果</td>
</tr>
<tr>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
</tr>
</tbody></table>
<h2 id="最后卷积层溢出"><a href="#最后卷积层溢出" class="headerlink" title="最后卷积层溢出"></a>最后卷积层溢出</h2><p>此时去水印已经有一定效果，但是在纯色区域和动态区域出现了疑似像素值溢出的彩色条带状区域。</p>
<div id="dplayer9" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer9"),"video":{"url":"/2025/watermark_removal_tool/明显的白色溢出.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script>

<p>考虑原因可能是网络最后一层是卷积层，输出的值没有范围限制，因此在后面追加了一个tanh层，现在RecurrentUNet类变成这样（只是在__init__和生成帧的两个位置改了两行）</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RecurrentUNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, out_channels=<span class="number">3</span>, features=[<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span>):</span><br><span class="line">        <span class="built_in">super</span>(RecurrentUNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.downs = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.ups = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编码器</span></span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">            <span class="variable language_">self</span>.downs.append(ConvBlock(in_channels, feature))</span><br><span class="line">            in_channels = feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ConvLSTM瓶颈</span></span><br><span class="line">        <span class="variable language_">self</span>.bottleneck_dim = features[-<span class="number">1</span>]</span><br><span class="line">        <span class="variable language_">self</span>.conv_lstm = ConvLSTMCell(input_dim=<span class="variable language_">self</span>.bottleneck_dim,</span><br><span class="line">                                      hidden_dim=<span class="variable language_">self</span>.bottleneck_dim,</span><br><span class="line">                                      kernel_size=(<span class="number">3</span>, <span class="number">3</span>), bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码器</span></span><br><span class="line">        in_channels = features[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> <span class="built_in">reversed</span>(features):</span><br><span class="line">            <span class="variable language_">self</span>.ups.append(nn.ConvTranspose2d(in_channels, feature, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">            <span class="variable language_">self</span>.ups.append(ConvBlock(feature * <span class="number">2</span>, feature))</span><br><span class="line">            in_channels = feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出</span></span><br><span class="line">        <span class="variable language_">self</span>.final_conv = nn.Conv2d(features[<span class="number">0</span>], out_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.tanh = nn.Tanh()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, hidden_state=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 视频片段x的期望形状:[batch_size, sequence_length, Channels, H, W]</span></span><br><span class="line">        batch_size, seq_len, _, H, W = x.shape</span><br><span class="line">        <span class="keyword">if</span> hidden_state <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            bottleneck_h, bottleneck_w = H // (<span class="number">2</span> ** (<span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>)), W // (<span class="number">2</span> ** (<span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>))</span><br><span class="line">            hidden_state = <span class="variable language_">self</span>.conv_lstm.init_hidden(batch_size, (bottleneck_h, bottleneck_w))</span><br><span class="line">        outputs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 序列帧循环</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(seq_len):</span><br><span class="line">            current_frame = x[:, t, :, :, :]</span><br><span class="line">            skip_connections_t = []</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 编码器</span></span><br><span class="line">            <span class="keyword">for</span> i, down <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.downs):</span><br><span class="line">                current_frame = down(current_frame)</span><br><span class="line">                skip_connections_t.append(current_frame)</span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>:</span><br><span class="line">                    current_frame = <span class="variable language_">self</span>.pool(current_frame)</span><br><span class="line">            <span class="comment"># ConvLSTM</span></span><br><span class="line">            h, c = <span class="variable language_">self</span>.conv_lstm(input_tensor=current_frame, cur_state=hidden_state)</span><br><span class="line">            hidden_state = (h, c)</span><br><span class="line">            current_frame = h</span><br><span class="line">            <span class="comment"># 反转跳跃连接列表</span></span><br><span class="line">            skip_connections_t = skip_connections_t[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 解码器</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.ups), <span class="number">2</span>):</span><br><span class="line">                current_frame = <span class="variable language_">self</span>.ups[i](current_frame)</span><br><span class="line">                skip_connection = skip_connections_t[i // <span class="number">2</span>]</span><br><span class="line">                <span class="comment"># 如果池化导致奇数尺寸，上采样后的尺寸与跳跃连接不匹配，则强制修改尺寸</span></span><br><span class="line">                <span class="keyword">if</span> current_frame.shape != skip_connection.shape:</span><br><span class="line">                    current_frame = nn.functional.interpolate(current_frame, size=skip_connection.shape[<span class="number">2</span>:])</span><br><span class="line">                concat_skip = torch.cat((skip_connection, current_frame), dim=<span class="number">1</span>)</span><br><span class="line">                current_frame = <span class="variable language_">self</span>.ups[i + <span class="number">1</span>](concat_skip)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 生成帧</span></span><br><span class="line">            frame_output = <span class="variable language_">self</span>.tanh(<span class="variable language_">self</span>.final_conv(current_frame))</span><br><span class="line">            outputs.append(frame_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.stack(outputs, dim=<span class="number">1</span>), hidden_state</span><br></pre></td></tr></table></figure>

<p>经过10轮的训练和测试，溢出问题得到解决：</p>
<table>
<thead>
<tr>
<th align="center"><div id="dplayer10" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer10"),"video":{"url":"/2025/watermark_removal_tool/epoch5_14938_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
<th align="center"><div id="dplayer11" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer11"),"video":{"url":"/2025/watermark_removal_tool/epoch10_14938_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
<th align="center"><div id="dplayer12" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer12"),"video":{"url":"/2025/watermark_removal_tool/epoch10_0628_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
</tr>
</thead>
<tbody><tr>
<td align="center">训练5轮去水印效果</td>
<td align="center">训练10轮去水印效果</td>
<td align="center">与前面的测试作比较</td>
</tr>
<tr>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
</tr>
</tbody></table>
<p>看起来训练轮次的增加效果不是那么明显，在继续训练的同时排查一下是不是激活函数导致的梯度消失问题。以及考虑是否是损失函数的缺陷，考虑增加对抗损失？</p>
<h2 id="梯度消失和可视化"><a href="#梯度消失和可视化" class="headerlink" title="梯度消失和可视化"></a>梯度消失和可视化</h2><p>对于梯度消失问题，用TensorBoard进行参数可视化，检查梯度范数。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 记录梯度范数到TensorBoard，在backward()和step()之间</span></span><br><span class="line">    <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">        <span class="keyword">if</span> param.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 使用writer.add_scalar来记录，标签格式 &#x27;grads/层名&#x27; 可以在 TensorBoard 中分组</span></span><br><span class="line">            writer.add_scalar(<span class="string">f&#x27;grads/<span class="subst">&#123;name&#125;</span>_norm&#x27;</span>, param.grad.norm(<span class="number">2</span>), epoch)</span><br><span class="line">    <span class="comment"># 记录总的梯度范数，以监控梯度爆炸</span></span><br><span class="line">    total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>))</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;grads/total_norm&#x27;</span>, total_norm, epoch)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结束，关闭writer</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>此时在终端输入启动命令即可在web查看具体图表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=runs</span><br></pre></td></tr></table></figure>

<p>得到的数据如下，发生梯度消失的可能性比较大，特别是ConvLSTM梯度已经到-7次的数量级，很有可能与此处使用的多个sigmoid和tanh激活函数有关。</p>
<table>
<thead>
<tr>
<th align="center"><img src="/2025/watermark_removal_tool/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20250816140036.png"></th>
<th align="center"><img src="/2025/watermark_removal_tool/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20250816140051.png"></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
</tr>
</tbody></table>
<p>考虑增加应该跳跃连接来让梯度传播跳过ConvLSTM层？</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ConvLSTM</span></span><br><span class="line">h, c = <span class="variable language_">self</span>.conv_lstm(input_tensor=current_frame, cur_state=hidden_state)</span><br><span class="line">hidden_state = (h, c)</span><br><span class="line"><span class="comment">#下一行为改动内容，原来是current_frame = h</span></span><br><span class="line">current_frame = h + current_frame</span><br></pre></td></tr></table></figure>

<p>反正先试一下，在10轮的基础上继续训练一轮</p>
<table>
<thead>
<tr>
<th align="center"><div id="dplayer13" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer13"),"video":{"url":"/2025/watermark_removal_tool/epoch10_14938_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
<th align="center"><div id="dplayer14" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer14"),"video":{"url":"/2025/watermark_removal_tool/epoch11_14938_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
</tr>
</thead>
<tbody><tr>
<td align="center">原来10轮模型效果</td>
<td align="center">改动后训练1轮也就是第11轮效果</td>
</tr>
<tr>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
</tr>
</tbody></table>
<p>效果不太明显，同时发生了图片整体的偏色，当然也不排除训练次数不够的原因，有待继续训练测试，下面是梯度图像</p>
<table>
<thead>
<tr>
<th align="center"><img src="/2025/watermark_removal_tool/%E4%BF%A1%E6%88%AA%E5%9B%BE_20250816151838.png"></th>
<th align="center"><img src="/2025/watermark_removal_tool/%E4%BF%A1%E6%88%AA%E5%9B%BE_20250816151901.png"></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
</tr>
</tbody></table>
<h2 id="对抗损失函数"><a href="#对抗损失函数" class="headerlink" title="对抗损失函数"></a>对抗损失函数</h2><p>使用多层3D卷积网络作为判别器的对抗网络的推理作为损失函数<br>train_gan.py:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms.functional <span class="keyword">as</span> TF</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> train <span class="keyword">import</span> RecurrentUNet, VideoDataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VideoDiscriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, features=[<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        layers = []</span><br><span class="line">        <span class="comment"># 3D卷积输入视频片段[Batch, Channels, Time, Height, Width]，卷积核在时间维度上覆盖了3帧，在空间高度上覆盖4个像素</span></span><br><span class="line">        <span class="comment"># stride滑动步长，在时间维度上每次只移动1帧，在空间上每次移动2个像素，起到下采样的作用</span></span><br><span class="line">        <span class="comment"># padding输入视频数据块的三个维度的两侧填充0</span></span><br><span class="line">        layers.append(nn.Conv3d(in_channels, features[<span class="number">0</span>], kernel_size=(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>), stride=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">        <span class="comment"># inplace=True会直接在存储输入数据的内存上进行计算并覆盖，节省一些GPU显存</span></span><br><span class="line">        layers.append(nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(features) - <span class="number">1</span>):</span><br><span class="line">            layers.append(nn.Conv3d(features[i], features[i + <span class="number">1</span>],kernel_size=(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>), stride=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>))</span><br><span class="line">            layers.append(nn.InstanceNorm3d(features[i + <span class="number">1</span>]))</span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">        layers.append(nn.Conv3d(features[-<span class="number">1</span>], <span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>), stride=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">        <span class="variable language_">self</span>.model = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.model(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    lr_gen = <span class="number">2e-4</span></span><br><span class="line">    lr_disc = <span class="number">2e-4</span></span><br><span class="line">    L1_weigth = <span class="number">100</span></span><br><span class="line">    batch_size = <span class="number">2</span></span><br><span class="line">    epochs = <span class="number">50</span></span><br><span class="line">    sequence_len = <span class="number">4</span></span><br><span class="line">    size = (<span class="number">480</span>, <span class="number">270</span>)</span><br><span class="line">    dataset_loader_workers = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集路径</span></span><br><span class="line">    dataset_path = <span class="string">&quot;D:\Dataset&quot;</span></span><br><span class="line">    <span class="comment"># 继续训练时加载模型路径和已完成轮次，输入0则从零开始训练</span></span><br><span class="line">    load_model_epoch = <span class="number">0</span></span><br><span class="line">    load_model_path_gen = <span class="string">&quot;&quot;</span></span><br><span class="line">    load_model_path_disc = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Using device: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    gen = RecurrentUNet(in_channels=<span class="number">4</span>, out_channels=<span class="number">3</span>).to(device)</span><br><span class="line">    disc = VideoDiscriminator(in_channels=<span class="number">3</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> load_model_epoch != <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loading Generator from <span class="subst">&#123;load_model_path_gen&#125;</span>&quot;</span>)</span><br><span class="line">        gen.load_state_dict(torch.load(load_model_path_gen, map_location=device))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loading Discriminator from <span class="subst">&#123;load_model_path_disc&#125;</span>&quot;</span>)</span><br><span class="line">        disc.load_state_dict(torch.load(load_model_path_disc, map_location=device))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Adam优化器，学习率lr，beta1默认值0.9的动量大约是过去10个时间步梯度的平均，降低到0.5降低动量惯性</span></span><br><span class="line">    <span class="comment"># beta2默认值0.999的二阶矩估计大约是过去1000个时间步梯度平方的平均，保持较高的值有助于保持自适应学习率的稳定性，防止因为单次梯度爆炸而导致学习率剧烈变化</span></span><br><span class="line">    opt_gen = optim.Adam(gen.parameters(), lr=lr_gen, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line">    opt_disc = optim.Adam(disc.parameters(), lr=lr_disc, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line">    <span class="comment"># 二元交叉熵和L1损失函数</span></span><br><span class="line">    adversarial_loss_fn = nn.BCEWithLogitsLoss()</span><br><span class="line">    l1_loss_fn = nn.L1Loss()</span><br><span class="line"></span><br><span class="line">    num_params_gen = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> gen.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">    num_params_disc = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> disc.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Generator has <span class="subst">&#123;num_params_gen:,&#125;</span> trainable parameters.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Discriminator has <span class="subst">&#123;num_params_disc:,&#125;</span> trainable parameters.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Preparing dataset...&quot;</span>)</span><br><span class="line">    train_dataset = VideoDataset(root_dir=dataset_path, sequence_length=sequence_len, size=size)</span><br><span class="line">    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>,num_workers=dataset_loader_workers, pin_memory=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Start training...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(load_model_epoch, epochs):</span><br><span class="line">        total_loss_g = <span class="number">0.0</span></span><br><span class="line">        total_loss_d = <span class="number">0.0</span></span><br><span class="line">        gen.train()</span><br><span class="line">        disc.train()</span><br><span class="line">        <span class="keyword">with</span> tqdm(total=<span class="built_in">len</span>(train_loader), desc=<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>&quot;</span>, unit=<span class="string">&quot;batch&quot;</span>) <span class="keyword">as</span> pbar:</span><br><span class="line">            <span class="keyword">for</span> batch_idx, (masked_seq, clips_seq, mask_seq) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">                <span class="comment"># masked_seq: [B, T, 4, H, W], clips_seq: [B, T, 3, H, W]</span></span><br><span class="line">                masked_seq = masked_seq.to(device)</span><br><span class="line">                clips_seq = clips_seq.to(device)</span><br><span class="line">                mask_seq = mask_seq.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># disc训练</span></span><br><span class="line">                clips_fake, _ = gen(masked_seq)</span><br><span class="line">                opt_disc.zero_grad()</span><br><span class="line">                <span class="comment"># 将视频维度从[B, T, C, H, W]转换到[B, C, T, H, W]以匹配Conv3d</span></span><br><span class="line">                real_clip_for_disc = clips_seq.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">                fake_clip_for_disc = clips_fake.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">                <span class="comment"># 判别器分别推理真实视频与全1张量、虚假视频与全0张量，计算二元交叉熵损失</span></span><br><span class="line">                disc_real = disc(real_clip_for_disc)</span><br><span class="line">                loss_disc_real = adversarial_loss_fn(disc_real, torch.ones_like(disc_real))</span><br><span class="line">                <span class="comment"># 用 .detach() 阻止梯度传回生成器</span></span><br><span class="line">                disc_fake = disc(fake_clip_for_disc.detach())</span><br><span class="line">                loss_disc_fake = adversarial_loss_fn(disc_fake, torch.zeros_like(disc_fake))</span><br><span class="line">                <span class="comment"># 判别器总损失</span></span><br><span class="line">                loss_disc = (loss_disc_real + loss_disc_fake) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">                loss_disc.backward()</span><br><span class="line">                opt_disc.step()</span><br><span class="line">                total_loss_d += loss_disc.item()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 训练生成器</span></span><br><span class="line">                opt_gen.zero_grad()</span><br><span class="line">                disc_fake_for_gen = disc(fake_clip_for_disc)</span><br><span class="line">                loss_g_adv = adversarial_loss_fn(disc_fake_for_gen, torch.ones_like(disc_fake_for_gen))</span><br><span class="line">                loss_g_l1 = l1_loss_fn(clips_fake, clips_seq) * L1_weigth</span><br><span class="line">                loss_g = loss_g_adv + loss_g_l1</span><br><span class="line">                loss_g.backward()</span><br><span class="line">                opt_gen.step()</span><br><span class="line">                total_loss_g += loss_g.item()</span><br><span class="line"></span><br><span class="line">                pbar.set_postfix(</span><br><span class="line">                    Loss_D=<span class="string">f&#x27;<span class="subst">&#123;loss_disc.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">                    Loss_G=<span class="string">f&#x27;<span class="subst">&#123;loss_g.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">                    G_adv=<span class="string">f&#x27;<span class="subst">&#123;loss_g_adv.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">                    G_L1=<span class="string">f&#x27;<span class="subst">&#123;loss_g_l1.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">                pbar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            avg_loss_g = total_loss_g / <span class="built_in">len</span>(train_loader)</span><br><span class="line">            avg_loss_d = total_loss_d / <span class="built_in">len</span>(train_loader)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;--- <span class="subst">&#123;datetime.datetime.now():%H:%M:%S&#125;</span>: Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span> avg_loss_G: <span class="subst">&#123;avg_loss_g:<span class="number">.4</span>f&#125;</span>, avg_loss_D: <span class="subst">&#123;avg_loss_d:<span class="number">.4</span>f&#125;</span> ---&quot;</span>)</span><br><span class="line"></span><br><span class="line">        pathlib.Path(<span class="string">&quot;model_gan&quot;</span>).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        torch.save(gen.state_dict(), <span class="string">f&quot;model_gan/gen_epoch_<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>.pth&quot;</span>)</span><br><span class="line">        torch.save(disc.state_dict(), <span class="string">f&quot;model_gan/disc_epoch_<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Completed!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用对抗损失后出现了一些进步和问题。14轮的模型在天空纯色区域明显好于13轮，但是出现少量溢出。再看15轮的结果就只剩溢出了……</p>
<table>
<thead>
<tr>
<th align="center"><div id="dplayer15" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer15"),"video":{"url":"/2025/watermark_removal_tool/GAN_epoch13_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
<th align="center"><div id="dplayer16" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer16"),"video":{"url":"/2025/watermark_removal_tool/GAN_epoch14_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
<th align="center"><div id="dplayer17" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer17"),"video":{"url":"/2025/watermark_removal_tool/GAN_epoch15_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></th>
</tr>
</thead>
<tbody><tr>
<td align="center">13轮</td>
<td align="center">14轮</td>
<td align="center">15轮</td>
</tr>
<tr>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
</tr>
</tbody></table>
<p>这部分训练是和前一节的梯度消失解决同时在两台电脑上测试的，因此并没有在convlstm引入跳跃连接，考虑到有可能由此引发这一问题，因此下面是加入了这一结构之后的训练效果。很明显溢出问题再次消失。</p>
<h2 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h2><p>虽然在convLSTM层加入了跳跃连接，但是在u-net部分的卷积层仍然出现了一定的梯度消失。不仅在梯度数据上，实际效果上从十几轮开始几乎就没有进步了。因此将残差网络的思想也加入这里，在卷积块加入了一个1*1的卷积层直连输入输出。卷积层的激活函数也从ReLU改为LeakyReLU，避免出现死亡节点。此外初始化遗忘门值改为1让信息全部通过，在初期避免进入饱和区（后来看这一点收效甚微，循环网络部分依然有严重的梯度消失）。判别器的第一层也加入了归一化层避免梯度消失或爆炸。</p>
<p>此外还增加了tensorboard对训练数据进行检测，包括梯度权重和损失的可视化。</p>
<p>由于额外加入了多个卷积层，对显存的占用更高，因此将输入图像序列长度sequence_len从4改为3，以能在我的8G显存3060ti上运行。由于这样减少了计算量，在我的电脑上单个epoch训练时间从70分钟缩短到55分钟。</p>
<p>由于改动巨大，github上开启了一个新的分支<code>dev</code>来和之前的代码<code>main</code>相区别。如果后续再有大规模修改这部分内容将以<code>GAN_GRAD</code>分支保存并在<code>dev</code>继续改进。</p>
<p>tarin.py:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms.functional <span class="keyword">as</span> TF</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvBlock, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.convblock = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> in_channels != out_channels:</span><br><span class="line">            <span class="variable language_">self</span>.shortcut = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(out_channels))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.shortcut = nn.Identity()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.final_activation = nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = <span class="variable language_">self</span>.convblock(x) + <span class="variable language_">self</span>.shortcut(x)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.final_activation(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvLSTMCell</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, kernel_size, bias</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvLSTMCell, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.input_dim = input_dim</span><br><span class="line">        <span class="variable language_">self</span>.hidden_dim = hidden_dim</span><br><span class="line">        <span class="variable language_">self</span>.kernel_size = kernel_size</span><br><span class="line">        <span class="variable language_">self</span>.padding = kernel_size[<span class="number">0</span>] // <span class="number">2</span>, kernel_size[<span class="number">1</span>] // <span class="number">2</span></span><br><span class="line">        <span class="variable language_">self</span>.bias = bias</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将输入门、遗忘门、输出门和细胞门的卷积操作合并计算</span></span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels=<span class="variable language_">self</span>.input_dim + <span class="variable language_">self</span>.hidden_dim,</span><br><span class="line">                              out_channels=<span class="number">4</span> * <span class="variable language_">self</span>.hidden_dim,  <span class="comment"># 4 for i, f, o, g gates</span></span><br><span class="line">                              kernel_size=<span class="variable language_">self</span>.kernel_size,</span><br><span class="line">                              padding=<span class="variable language_">self</span>.padding,</span><br><span class="line">                              bias=<span class="variable language_">self</span>.bias)</span><br><span class="line">        <span class="keyword">if</span> bias:</span><br><span class="line">            <span class="comment"># 初始化遗忘门的偏置为1.0，尽可能地保持打开</span></span><br><span class="line">            forget_gate_bias_start = hidden_dim</span><br><span class="line">            forget_gate_bias_end = <span class="number">2</span> * hidden_dim</span><br><span class="line">            <span class="variable language_">self</span>.conv.bias.data[forget_gate_bias_start:forget_gate_bias_end].fill_(<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_tensor, cur_state</span>):</span><br><span class="line">        h_cur, c_cur = cur_state</span><br><span class="line">        combined = torch.cat([input_tensor, h_cur], dim=<span class="number">1</span>)</span><br><span class="line">        combined_conv = <span class="variable language_">self</span>.conv(combined)</span><br><span class="line">        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, <span class="variable language_">self</span>.hidden_dim, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算4*门</span></span><br><span class="line">        i = torch.sigmoid(cc_i)</span><br><span class="line">        f = torch.sigmoid(cc_f)</span><br><span class="line">        o = torch.sigmoid(cc_o)</span><br><span class="line">        g = torch.tanh(cc_g)</span><br><span class="line">        c_next = f * c_cur + i * g</span><br><span class="line">        h_next = o * torch.tanh(c_next)</span><br><span class="line">        <span class="keyword">return</span> h_next, c_next</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self, batch_size, image_size</span>):</span><br><span class="line">        height, width = image_size</span><br><span class="line">        <span class="keyword">return</span> (torch.zeros(batch_size, <span class="variable language_">self</span>.hidden_dim, height, width, device=<span class="variable language_">self</span>.conv.weight.device),</span><br><span class="line">                torch.zeros(batch_size, <span class="variable language_">self</span>.hidden_dim, height, width, device=<span class="variable language_">self</span>.conv.weight.device))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RecurrentUNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, out_channels=<span class="number">3</span>, features=[<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span>):</span><br><span class="line">        <span class="built_in">super</span>(RecurrentUNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.downs = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.ups = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编码器</span></span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">            <span class="variable language_">self</span>.downs.append(ConvBlock(in_channels, feature))</span><br><span class="line">            in_channels = feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ConvLSTM瓶颈</span></span><br><span class="line">        <span class="variable language_">self</span>.bottleneck_dim = features[-<span class="number">1</span>]</span><br><span class="line">        <span class="variable language_">self</span>.conv_lstm = ConvLSTMCell(input_dim=<span class="variable language_">self</span>.bottleneck_dim,</span><br><span class="line">                                      hidden_dim=<span class="variable language_">self</span>.bottleneck_dim,</span><br><span class="line">                                      kernel_size=(<span class="number">3</span>, <span class="number">3</span>), bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码器</span></span><br><span class="line">        in_channels = features[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> <span class="built_in">reversed</span>(features):</span><br><span class="line">            <span class="variable language_">self</span>.ups.append(nn.ConvTranspose2d(in_channels, feature, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">            <span class="variable language_">self</span>.ups.append(ConvBlock(feature * <span class="number">2</span>, feature))</span><br><span class="line">            in_channels = feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出</span></span><br><span class="line">        <span class="variable language_">self</span>.final_conv = nn.Conv2d(features[<span class="number">0</span>], out_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.tanh = nn.Tanh()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, hidden_state=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 视频片段x的期望形状:[batch_size, sequence_length, Channels, H, W]</span></span><br><span class="line">        batch_size, seq_len, _, H, W = x.shape</span><br><span class="line">        <span class="keyword">if</span> hidden_state <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            bottleneck_h, bottleneck_w = H // (<span class="number">2</span> ** (<span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>)), W // (<span class="number">2</span> ** (<span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>))</span><br><span class="line">            hidden_state = <span class="variable language_">self</span>.conv_lstm.init_hidden(batch_size, (bottleneck_h, bottleneck_w))</span><br><span class="line">        outputs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 序列帧循环</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(seq_len):</span><br><span class="line">            current_frame = x[:, t, :, :, :]</span><br><span class="line">            skip_connections_t = []</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 编码器</span></span><br><span class="line">            <span class="keyword">for</span> i, down <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.downs):</span><br><span class="line">                current_frame = down(current_frame)</span><br><span class="line">                skip_connections_t.append(current_frame)</span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(<span class="variable language_">self</span>.downs) - <span class="number">1</span>:</span><br><span class="line">                    current_frame = <span class="variable language_">self</span>.pool(current_frame)</span><br><span class="line">            <span class="comment"># ConvLSTM</span></span><br><span class="line">            h, c = <span class="variable language_">self</span>.conv_lstm(input_tensor=current_frame, cur_state=hidden_state)</span><br><span class="line">            hidden_state = (h, c)</span><br><span class="line">            current_frame = h + current_frame</span><br><span class="line">            <span class="comment"># 反转跳跃连接列表</span></span><br><span class="line">            skip_connections_t = skip_connections_t[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 解码器</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.ups), <span class="number">2</span>):</span><br><span class="line">                current_frame = <span class="variable language_">self</span>.ups[i](current_frame)</span><br><span class="line">                skip_connection = skip_connections_t[i // <span class="number">2</span>]</span><br><span class="line">                <span class="comment"># 如果池化导致奇数尺寸，上采样后的尺寸与跳跃连接不匹配，则强制修改尺寸</span></span><br><span class="line">                <span class="keyword">if</span> current_frame.shape != skip_connection.shape:</span><br><span class="line">                    current_frame = nn.functional.interpolate(current_frame, size=skip_connection.shape[<span class="number">2</span>:])</span><br><span class="line">                concat_skip = torch.cat((skip_connection, current_frame), dim=<span class="number">1</span>)</span><br><span class="line">                current_frame = <span class="variable language_">self</span>.ups[i + <span class="number">1</span>](concat_skip)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 生成帧</span></span><br><span class="line">            frame_output = <span class="variable language_">self</span>.tanh(<span class="variable language_">self</span>.final_conv(current_frame))</span><br><span class="line">            outputs.append(frame_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.stack(outputs, dim=<span class="number">1</span>), hidden_state</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VideoDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, sequence_length=<span class="number">10</span>, transform=<span class="literal">None</span>, size=(<span class="params"><span class="number">480</span>, <span class="number">270</span></span>)</span>):</span><br><span class="line">        <span class="variable language_">self</span>.root_dir = pathlib.Path(root_dir)</span><br><span class="line">        <span class="variable language_">self</span>.clips_dir = <span class="variable language_">self</span>.root_dir / <span class="string">&#x27;clips&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.mask_clips_dir = <span class="variable language_">self</span>.root_dir / <span class="string">&#x27;mask_clips&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.mask_dir = <span class="variable language_">self</span>.root_dir / <span class="string">&#x27;masks&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.clips_files = <span class="built_in">sorted</span>([p <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.clips_dir.glob(<span class="string">&#x27;*.mp4&#x27;</span>)])</span><br><span class="line">        <span class="variable language_">self</span>.mask_clips_files = <span class="built_in">sorted</span>([p <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.mask_clips_dir.glob(<span class="string">&#x27;*.mp4&#x27;</span>)])</span><br><span class="line">        <span class="variable language_">self</span>.mask_files = <span class="built_in">sorted</span>([p <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.mask_dir.glob(<span class="string">&#x27;*.png&#x27;</span>)])</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.clips_files) == <span class="built_in">len</span>(<span class="variable language_">self</span>.mask_clips_files) == <span class="built_in">len</span>(<span class="variable language_">self</span>.mask_files), <span class="string">&quot;The number of dataset files does not match!&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.sequence_length = sequence_length</span><br><span class="line">        <span class="variable language_">self</span>.transform = transform</span><br><span class="line">        <span class="comment"># 输入格式(width, height)，PyTorch(height, width)</span></span><br><span class="line">        <span class="variable language_">self</span>.target_size = size</span><br><span class="line">        <span class="variable language_">self</span>.target_size_torch = (size[<span class="number">1</span>], size[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.clips_files)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        clips_path = <span class="built_in">str</span>(<span class="variable language_">self</span>.clips_files[idx])</span><br><span class="line">        mask_clips_path = <span class="built_in">str</span>(<span class="variable language_">self</span>.mask_clips_files[idx])</span><br><span class="line">        mask_path = <span class="built_in">str</span>(<span class="variable language_">self</span>.mask_files[idx])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">read_and_resize_frames</span>(<span class="params">video_path, num_frames, size</span>):</span><br><span class="line">            cap = cv2.VideoCapture(video_path)</span><br><span class="line">            total_frames = <span class="built_in">int</span>(cap.get(cv2.CAP_PROP_FRAME_COUNT))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> total_frames &lt; num_frames:</span><br><span class="line">                cap.release()</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Video <span class="subst">&#123;video_path&#125;</span> : total_frames (<span class="subst">&#123;total_frames&#125;</span>) &lt; num_frames (<span class="subst">&#123;num_frames&#125;</span>)。&quot;</span>)</span><br><span class="line"></span><br><span class="line">            frames = []</span><br><span class="line">            start_frame_index = <span class="number">0</span></span><br><span class="line">            cap.<span class="built_in">set</span>(cv2.CAP_PROP_POS_FRAMES, start_frame_index)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_frames):</span><br><span class="line">                ret, frame = cap.read()</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                frame_resized = cv2.resize(frame, size, interpolation=cv2.INTER_AREA)</span><br><span class="line"></span><br><span class="line">                frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)</span><br><span class="line">                frames.append(TF.to_tensor(frame_rgb))</span><br><span class="line">            cap.release()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(frames) != num_frames:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Read frame failed: <span class="subst">&#123;video_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> torch.stack(frames)</span><br><span class="line"></span><br><span class="line">        clips_seq = read_and_resize_frames(clips_path, <span class="variable language_">self</span>.sequence_length, <span class="variable language_">self</span>.target_size)</span><br><span class="line">        masked_seq = read_and_resize_frames(mask_clips_path, <span class="variable language_">self</span>.sequence_length, <span class="variable language_">self</span>.target_size)</span><br><span class="line">        mask_image = torchvision.io.read_image(<span class="built_in">str</span>(mask_path))</span><br><span class="line">        mask_image_resized = TF.resize(mask_image, <span class="variable language_">self</span>.target_size_torch, antialias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 归一化</span></span><br><span class="line">        clips_seq = clips_seq * <span class="number">2.0</span> - <span class="number">1.0</span></span><br><span class="line">        masked_seq = masked_seq * <span class="number">2.0</span> - <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">        mask_seq = mask_image_resized.<span class="built_in">float</span>() / <span class="number">255.0</span></span><br><span class="line">        mask_seq[mask_seq &gt; <span class="number">0.5</span>] = <span class="number">1.0</span></span><br><span class="line">        mask_seq[mask_seq &lt;= <span class="number">0.5</span>] = <span class="number">0.0</span></span><br><span class="line">        mask_seq = mask_seq.unsqueeze(<span class="number">0</span>).repeat(<span class="variable language_">self</span>.sequence_length, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        mask_seq = mask_seq[:, <span class="number">0</span>:<span class="number">1</span>, :, :]</span><br><span class="line">        masked_seq = torch.cat((masked_seq, mask_seq), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.transform:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> masked_seq, clips_seq, mask_seq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    lr = <span class="number">1e-4</span></span><br><span class="line">    batch_size = <span class="number">2</span></span><br><span class="line">    epochs = <span class="number">50</span></span><br><span class="line">    sequence_len = <span class="number">4</span></span><br><span class="line">    size = (<span class="number">480</span>, <span class="number">270</span>)</span><br><span class="line">    dataset_loader_workers = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">    dataset_path = <span class="string">r&quot;D:/Dataset&quot;</span></span><br><span class="line">    <span class="comment"># 继续训练时加载模型路径和已完成轮次，路径为空字符串则从零开始训练且设置的轮次无效</span></span><br><span class="line">    load_model_path = <span class="string">r&quot;model/epoch_10.pth&quot;</span></span><br><span class="line">    load_model_epoch = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    writer = SummaryWriter(<span class="string">r&#x27;runs/gradient_monitoring&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Using device: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line">    model = RecurrentUNet(in_channels=<span class="number">4</span>, out_channels=<span class="number">3</span>).to(device)</span><br><span class="line">    <span class="keyword">if</span> load_model_path == <span class="string">&quot;&quot;</span>:</span><br><span class="line">        load_model_epoch = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model.load_state_dict(torch.load(load_model_path, map_location=device))</span><br><span class="line"></span><br><span class="line">    criterion = nn.L1Loss()</span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=lr)</span><br><span class="line"></span><br><span class="line">    num_params = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Model has <span class="subst">&#123;num_params:,&#125;</span> trainable parameters.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Preparing dataset...&quot;</span>)</span><br><span class="line">    train_dataset = VideoDataset(root_dir=dataset_path, sequence_length=sequence_len, size=size)</span><br><span class="line">    train_loader = DataLoader(</span><br><span class="line">        dataset=train_dataset,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=<span class="literal">True</span>,</span><br><span class="line">        num_workers=dataset_loader_workers,</span><br><span class="line">        pin_memory=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Start training...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(load_model_epoch, epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        total_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">with</span> tqdm(total=<span class="built_in">len</span>(train_loader), desc=<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>&quot;</span>, unit=<span class="string">&quot;batch&quot;</span>) <span class="keyword">as</span> pbar:</span><br><span class="line">            <span class="keyword">for</span> batch_idx, (masked_seq, clips_seq, mask_seq) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">                masked_seq = masked_seq.to(device)</span><br><span class="line">                clips_seq = clips_seq.to(device)</span><br><span class="line">                mask_seq = mask_seq.to(device)</span><br><span class="line"></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                restored_seq, h_last = model(masked_seq)</span><br><span class="line"></span><br><span class="line">                loss = criterion(restored_seq, clips_seq)</span><br><span class="line">                loss.backward()</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">                    <span class="keyword">if</span> param.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        <span class="comment"># 使用writer.add_scalar来记录，标签格式 &#x27;grads/层名&#x27; 可以在 TensorBoard 中分组</span></span><br><span class="line">                        writer.add_scalar(<span class="string">f&#x27;grads/<span class="subst">&#123;name&#125;</span>_norm&#x27;</span>, param.grad.norm(<span class="number">2</span>), epoch)</span><br><span class="line">                <span class="comment"># 记录总的梯度范数，以监控梯度爆炸</span></span><br><span class="line">                total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>))</span><br><span class="line">                writer.add_scalar(<span class="string">&#x27;grads/total_norm&#x27;</span>, total_norm, epoch)</span><br><span class="line"></span><br><span class="line">                optimizer.step()</span><br><span class="line">                total_loss += loss.item()</span><br><span class="line"></span><br><span class="line">                pbar.set_postfix(loss=<span class="string">f&#x27;<span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">                pbar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        avg_loss = total_loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;--- <span class="subst">&#123;datetime.datetime.now():%H:%M:%S&#125;</span>: Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span> avg_loss: <span class="subst">&#123;avg_loss:<span class="number">.4</span>f&#125;</span> ---&quot;</span>)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">f&quot;model/epoch_<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Completed!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>tarin_GAN.py:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms.functional <span class="keyword">as</span> TF</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> train <span class="keyword">import</span> RecurrentUNet, VideoDataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VideoDiscriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, features=[<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        layers = []</span><br><span class="line">        <span class="comment"># 3D卷积输入视频片段[Batch, Channels, Time, Height, Width]，卷积核在时间维度上覆盖了3帧，在空间高度上覆盖4个像素</span></span><br><span class="line">        <span class="comment"># stride滑动步长，在时间维度上每次只移动1帧，在空间上每次移动2个像素，起到下采样的作用</span></span><br><span class="line">        <span class="comment"># padding输入视频数据块的三个维度的两侧填充0</span></span><br><span class="line">        layers.append(nn.Conv3d(in_channels, features[<span class="number">0</span>], kernel_size=(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>), stride=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">        layers.append(nn.InstanceNorm3d(features[<span class="number">0</span>]))</span><br><span class="line">        <span class="comment"># inplace=True会直接在存储输入数据的内存上进行计算并覆盖，节省一些GPU显存</span></span><br><span class="line">        layers.append(nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(features) - <span class="number">1</span>):</span><br><span class="line">            layers.append(nn.Conv3d(features[i], features[i + <span class="number">1</span>],kernel_size=(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>), stride=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>))</span><br><span class="line">            layers.append(nn.InstanceNorm3d(features[i + <span class="number">1</span>]))</span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">        layers.append(nn.Conv3d(features[-<span class="number">1</span>], <span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>), stride=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">        <span class="variable language_">self</span>.model = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.model(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    lr_gen = <span class="number">2e-4</span></span><br><span class="line">    lr_disc = <span class="number">2e-4</span></span><br><span class="line">    L1_weigth = <span class="number">100</span></span><br><span class="line">    batch_size = <span class="number">2</span></span><br><span class="line">    epochs = <span class="number">100</span></span><br><span class="line">    sequence_len = <span class="number">3</span></span><br><span class="line">    size = (<span class="number">480</span>, <span class="number">270</span>)</span><br><span class="line">    dataset_loader_workers = <span class="number">6</span></span><br><span class="line">    Gradient_intervals = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集和模型保存路径</span></span><br><span class="line">    dataset_path = <span class="string">r&quot;D:/Dataset&quot;</span></span><br><span class="line">    model_save_dir = <span class="string">r&quot;model_gan_2&quot;</span></span><br><span class="line">    <span class="comment"># 继续训练时加载模型路径和已完成轮次，输入0则从零开始训练</span></span><br><span class="line">    load_model_epoch = <span class="number">9</span></span><br><span class="line">    load_model_path_gen = <span class="string">r&quot;model_gan_2/gen_epoch_9.pth&quot;</span></span><br><span class="line">    load_model_path_disc = <span class="string">r&quot;model_gan_2/disc_epoch_9.pth&quot;</span></span><br><span class="line"></span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Using device: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    writer = SummaryWriter(<span class="string">&#x27;runs/GAN_2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    gen = RecurrentUNet(in_channels=<span class="number">4</span>, out_channels=<span class="number">3</span>).to(device)</span><br><span class="line">    disc = VideoDiscriminator(in_channels=<span class="number">3</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> load_model_epoch != <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loading Generator from <span class="subst">&#123;load_model_path_gen&#125;</span>&quot;</span>)</span><br><span class="line">        gen.load_state_dict(torch.load(load_model_path_gen, map_location=device))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loading Discriminator from <span class="subst">&#123;load_model_path_disc&#125;</span>&quot;</span>)</span><br><span class="line">        disc.load_state_dict(torch.load(load_model_path_disc, map_location=device))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Adam优化器，学习率lr，beta1默认值0.9的动量大约是过去10个时间步梯度的平均，降低到0.5降低动量惯性</span></span><br><span class="line">    <span class="comment"># beta2默认值0.999的二阶矩估计大约是过去1000个时间步梯度平方的平均，保持较高的值有助于保持自适应学习率的稳定性，防止因为单次梯度爆炸而导致学习率剧烈变化</span></span><br><span class="line">    opt_gen = optim.Adam(gen.parameters(), lr=lr_gen, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line">    opt_disc = optim.Adam(disc.parameters(), lr=lr_disc, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line">    <span class="comment"># 二元交叉熵和L1损失函数</span></span><br><span class="line">    adversarial_loss_fn = nn.BCEWithLogitsLoss()</span><br><span class="line">    l1_loss_fn = nn.L1Loss()</span><br><span class="line"></span><br><span class="line">    num_params_gen = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> gen.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">    num_params_disc = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> disc.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Generator has <span class="subst">&#123;num_params_gen:,&#125;</span> trainable parameters.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Discriminator has <span class="subst">&#123;num_params_disc:,&#125;</span> trainable parameters.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Preparing dataset...&quot;</span>)</span><br><span class="line">    train_dataset = VideoDataset(root_dir=dataset_path, sequence_length=sequence_len, size=size)</span><br><span class="line">    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>,num_workers=dataset_loader_workers, pin_memory=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    writer.add_graph(gen, <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))[<span class="number">0</span>].to(device))</span><br><span class="line">    writer.add_graph(disc, <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))[<span class="number">1</span>].permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>).to(device))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Start training...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(load_model_epoch, epochs):</span><br><span class="line">        total_loss_g = <span class="number">0.0</span></span><br><span class="line">        total_loss_d = <span class="number">0.0</span></span><br><span class="line">        total_loss_g_L1 = <span class="number">0.0</span></span><br><span class="line">        total_loss_g_adv = <span class="number">0.0</span></span><br><span class="line">        gen.train()</span><br><span class="line">        disc.train()</span><br><span class="line">        <span class="keyword">with</span> tqdm(total=<span class="built_in">len</span>(train_loader), desc=<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>&quot;</span>, unit=<span class="string">&quot;batch&quot;</span>) <span class="keyword">as</span> pbar:</span><br><span class="line">            <span class="keyword">for</span> batch_idx, (masked_seq, clips_seq, mask_seq) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">                <span class="comment"># masked_seq: [B, T, 4, H, W], clips_seq: [B, T, 3, H, W]</span></span><br><span class="line">                masked_seq = masked_seq.to(device)</span><br><span class="line">                clips_seq = clips_seq.to(device)</span><br><span class="line">                mask_seq = mask_seq.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># disc训练</span></span><br><span class="line">                clips_fake, _ = gen(masked_seq)</span><br><span class="line">                opt_disc.zero_grad()</span><br><span class="line">                <span class="comment"># 将视频维度从[B, T, C, H, W]转换到[B, C, T, H, W]以匹配Conv3d</span></span><br><span class="line">                real_clip_for_disc = clips_seq.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">                fake_clip_for_disc = clips_fake.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">                <span class="comment"># 判别器分别推理真实视频与全1张量、虚假视频与全0张量，计算二元交叉熵损失</span></span><br><span class="line">                disc_real = disc(real_clip_for_disc)</span><br><span class="line">                loss_disc_real = adversarial_loss_fn(disc_real, torch.ones_like(disc_real))</span><br><span class="line">                <span class="comment"># 用 .detach() 阻止梯度传回生成器</span></span><br><span class="line">                disc_fake = disc(fake_clip_for_disc.detach())</span><br><span class="line">                loss_disc_fake = adversarial_loss_fn(disc_fake, torch.zeros_like(disc_fake))</span><br><span class="line">                <span class="comment"># 判别器总损失</span></span><br><span class="line">                loss_disc = (loss_disc_real + loss_disc_fake) / <span class="number">2</span></span><br><span class="line">                loss_disc.backward()</span><br><span class="line">                <span class="comment"># 记录梯度权重</span></span><br><span class="line">                <span class="keyword">if</span> batch_idx % Gradient_intervals == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">for</span> name, param <span class="keyword">in</span> disc.named_parameters():</span><br><span class="line">                        <span class="keyword">if</span> param.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                            <span class="comment"># 使用 f-string 为每个梯度直方图创建唯一的、有组织的标签</span></span><br><span class="line">                            <span class="comment"># &#x27;Gradients/&#x27; 会在 TensorBoard 中创建一个名为 Gradients 的分组</span></span><br><span class="line">                            writer.add_histogram(</span><br><span class="line">                                tag=<span class="string">f&#x27;Grad_disc/<span class="subst">&#123;name&#125;</span>&#x27;</span>,values=param.grad,global_step=epoch * <span class="built_in">len</span>(train_loader) + batch_idx)</span><br><span class="line">                opt_disc.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 训练生成器</span></span><br><span class="line">                opt_gen.zero_grad()</span><br><span class="line">                disc_fake_for_gen = disc(fake_clip_for_disc)</span><br><span class="line">                loss_g_adv = adversarial_loss_fn(disc_fake_for_gen, torch.ones_like(disc_fake_for_gen))</span><br><span class="line">                loss_g_l1 = l1_loss_fn(clips_fake, clips_seq) * L1_weigth</span><br><span class="line">                loss_g = loss_g_adv + loss_g_l1</span><br><span class="line">                loss_g.backward()</span><br><span class="line">                <span class="keyword">if</span> batch_idx % Gradient_intervals == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">for</span> name, param <span class="keyword">in</span> gen.named_parameters():</span><br><span class="line">                        <span class="keyword">if</span> param.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                            writer.add_histogram(tag=<span class="string">f&#x27;Grad_gan/<span class="subst">&#123;name&#125;</span>&#x27;</span>,values=param.grad,global_step=epoch * <span class="built_in">len</span>(train_loader) + batch_idx)</span><br><span class="line">                opt_gen.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 统计记录</span></span><br><span class="line">                total_loss_g += loss_g.item()</span><br><span class="line">                total_loss_d += loss_disc.item()</span><br><span class="line">                total_loss_g_L1 += loss_g_l1.item()</span><br><span class="line">                total_loss_g_adv += loss_g_adv.item()</span><br><span class="line">                writer.add_scalar(<span class="string">&#x27;Loss/loss_g_l1&#x27;</span>, loss_g_l1.item(), epoch * <span class="built_in">len</span>(train_loader) + batch_idx)</span><br><span class="line">                writer.add_scalar(<span class="string">&#x27;Loss/loss_g_adv&#x27;</span>, loss_g_adv.item(), epoch * <span class="built_in">len</span>(train_loader) + batch_idx)</span><br><span class="line">                writer.add_scalar(<span class="string">&#x27;Loss/loss_g&#x27;</span>, loss_g.item(), epoch * <span class="built_in">len</span>(train_loader) + batch_idx)</span><br><span class="line">                writer.add_scalar(<span class="string">&#x27;Loss/loss_disc&#x27;</span>, loss_disc.item(), epoch * <span class="built_in">len</span>(train_loader) + batch_idx)</span><br><span class="line">                writer.add_scalar(<span class="string">&#x27;Loss/D_real&#x27;</span>, loss_disc_real.item(), epoch * <span class="built_in">len</span>(train_loader) + batch_idx)</span><br><span class="line">                writer.add_scalar(<span class="string">&#x27;Loss/D_fake&#x27;</span>, loss_disc_fake.item(), epoch * <span class="built_in">len</span>(train_loader) + batch_idx)</span><br><span class="line"></span><br><span class="line">                pbar.set_postfix(</span><br><span class="line">                    D_real=<span class="string">f&#x27;<span class="subst">&#123;loss_disc_real.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">                    D_fake=<span class="string">f&#x27;<span class="subst">&#123;loss_disc_fake.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">                    Loss_D=<span class="string">f&#x27;<span class="subst">&#123;loss_disc.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">                    Loss_G=<span class="string">f&#x27;<span class="subst">&#123;loss_g.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">                    G_adv=<span class="string">f&#x27;<span class="subst">&#123;loss_g_adv.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">                    G_L1=<span class="string">f&#x27;<span class="subst">&#123;loss_g_l1.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">                pbar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            avg_loss_g = total_loss_g / <span class="built_in">len</span>(train_loader)</span><br><span class="line">            avg_loss_d = total_loss_d / <span class="built_in">len</span>(train_loader)</span><br><span class="line">            avg_loss_g_L1 = total_loss_g_L1 / <span class="built_in">len</span>(train_loader)</span><br><span class="line">            avg_loss_d_adv = total_loss_g_adv / <span class="built_in">len</span>(train_loader)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;--- <span class="subst">&#123;datetime.datetime.now():%H:%M:%S&#125;</span>: Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span> avg_loss_G: <span class="subst">&#123;avg_loss_g:<span class="number">.4</span>f&#125;</span>, avg_loss_D: <span class="subst">&#123;avg_loss_d:<span class="number">.4</span>f&#125;</span>, avg_loss_g_L1: <span class="subst">&#123;avg_loss_g_L1:<span class="number">.4</span>f&#125;</span>, avg_loss_d_adv: <span class="subst">&#123;avg_loss_d_adv:<span class="number">.4</span>f&#125;</span> ---&quot;</span>)</span><br><span class="line"></span><br><span class="line">        pathlib.Path(<span class="string">&quot;model_gan&quot;</span>).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        torch.save(gen.state_dict(), <span class="string">f&quot;<span class="subst">&#123;model_save_dir&#125;</span>/gen_epoch_<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>.pth&quot;</span>)</span><br><span class="line">        torch.save(disc.state_dict(), <span class="string">f&quot;<span class="subst">&#123;model_save_dir&#125;</span>/disc_epoch_<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Completed!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>经过测试，效果提升极其显著。这里将前一两节内容结合得到的模型和多处改进的当前模型的推理结果进行对比，两者在5、10、20、30轮的效果分别如何：</p>
<table>
<thead>
<tr>
<th align="center">—</th>
<th align="center">仅在循环网络部分加入一处跳跃连接</th>
<th align="center">卷积层也加入残差网络等修改之后</th>
</tr>
</thead>
<tbody><tr>
<td align="center">5轮</td>
<td align="center"><div id="dplayer18" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer18"),"video":{"url":"/2025/watermark_removal_tool/GAN_1_5_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></td>
<td align="center"><div id="dplayer19" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer19"),"video":{"url":"/2025/watermark_removal_tool/GAN_2_5_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></td>
</tr>
<tr>
<td align="center">10轮</td>
<td align="center"><div id="dplayer20" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer20"),"video":{"url":"/2025/watermark_removal_tool/GAN_1_10_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></td>
<td align="center"><div id="dplayer21" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer21"),"video":{"url":"/2025/watermark_removal_tool/GAN_2_10_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></td>
</tr>
<tr>
<td align="center">20轮</td>
<td align="center"><div id="dplayer22" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer22"),"video":{"url":"/2025/watermark_removal_tool/GAN_1_20_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></td>
<td align="center">bad asset path...</td>
</tr>
<tr>
<td align="center">30轮</td>
<td align="center"><div id="dplayer24" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer24"),"video":{"url":"/2025/watermark_removal_tool/GAN_1_30_restored_video.mp4"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script></td>
<td align="center">bad asset path...</td>
</tr>
<tr>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
<td align="center"><img width=2000/></td>
</tr>
</tbody></table>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://www.triority.cc/">Triority</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://triority.cc/2025/watermark_removal_tool/">http://triority.cc/2025/watermark_removal_tool/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://triority.cc" target="_blank">Triority's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="post-meta__tags" href="/tags/C/">C++</a></div><div class="post_share"><div class="social-share" data-image="/img/0628.png" data-sites="twitter,wechat,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2025/Visual-SLAM/" title="本科毕业设计论文：巷道移动机器人SLAM技术研究"><div class="cover" style="background: /img/"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">本科毕业设计论文：巷道移动机器人SLAM技术研究</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/favicon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Triority</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">124</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">36</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Triority"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Triority" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:triority@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">The domain name of this website has been changed to triority.cc(Using CDN via cloudflare, recommended) / www.triority.cc(Connecting directly, works better in Chinese mainland). Please contact me if you have any questions.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BF%91%E6%9C%9F%E6%83%85%E5%86%B5"><span class="toc-number">1.</span> <span class="toc-text">近期情况</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B0%B4%E5%8D%B0%E6%95%B0%E6%8D%AE"><span class="toc-number">2.</span> <span class="toc-text">水印数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">3.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B%E5%92%8C%E6%95%88%E6%9E%9C%E8%AE%B0%E5%BD%95"><span class="toc-number">4.</span> <span class="toc-text">改进和效果记录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#RGB%E4%B8%89%E7%BB%B4%E8%BE%93%E5%85%A5"><span class="toc-number">4.1.</span> <span class="toc-text">RGB三维输入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RGB-Mask%E5%9B%9B%E7%BB%B4%E8%BE%93%E5%85%A5"><span class="toc-number">4.2.</span> <span class="toc-text">RGB+Mask四维输入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%90%8E%E5%8D%B7%E7%A7%AF%E5%B1%82%E6%BA%A2%E5%87%BA"><span class="toc-number">4.3.</span> <span class="toc-text">最后卷积层溢出</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">4.4.</span> <span class="toc-text">梯度消失和可视化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E6%8A%97%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">4.5.</span> <span class="toc-text">对抗损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C"><span class="toc-number">4.6.</span> <span class="toc-text">残差网络</span></a></li></ol></li></ol></div></div><div class="card-widget ads-wrap"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="100%" height=300 src="//music.163.com/outchain/player?type=0&id=9796678610&auto=0&height=430"></iframe></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2025 By Triority</div><div class="footer_custom_text">阿美莉卡ICP备114514号</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'HCrr1LolVdHjaQ03fiyQnqO4-gzGzoHsz',
      appKey: 'SQPN055DPf1nyNHqYj5SBoo2',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>